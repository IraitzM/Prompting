{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6a432f",
   "metadata": {},
   "source": [
    "Let's move forward with **Few-Shot prompting**. The idea behind few shot prompting is that you can create some examples on how the LLM should proceed when a new question arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Select a model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2efe34a",
   "metadata": {},
   "source": [
    "Let's create a template to our Question-Answer agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4cc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "question_template = PromptTemplate.from_template(\"Question: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786e1e6",
   "metadata": {},
   "source": [
    "Now we can simply invoke it and see the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8544bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammad Ali lived longer than Alan Turing.\n",
      "\n",
      "*   **Muhammad Ali:** 1942-2016 (74 years)\n",
      "*   **Alan Turing:** 1912-1954 (41 years)\n"
     ]
    }
   ],
   "source": [
    "chain = question_template | llm\n",
    "\n",
    "response = chain.invoke(input={\"question\" : \"Who lived longer, Muhammad Ali or Alan Turing?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c7650",
   "metadata": {},
   "source": [
    "Not exactly what we where looking for. We would like something more precise, just the name for example. We can try to instruct the model with the system prompt but we could also just simply exemplify the process and that way it might get how we would like to get the answer as well as the process to get there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852e66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When was the founder of craigslist born?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
    "        \"answer\": \"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b115e",
   "metadata": {},
   "source": [
    "[FewShotPromptingTemplate](https://python.langchain.com/docs/how_to/few_shot_examples/) allows to structure the query so that we do not have to repeat the process to make it simpler to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92acf2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are follow up questions needed here: Yes.\n",
      "Follow up: What are the strengths of LangChain?\n",
      "Intermediate Answer: LangChain is strong in its versatility, supporting a wide range of applications and integrations with various tools and models.\n",
      "Follow up: What are the strengths of LlamaIndex?\n",
      "Intermediate Answer: LlamaIndex excels in data indexing and retrieval, particularly for knowledge graphs and unstructured data sources, making it suitable for question answering and knowledge discovery tasks.\n",
      "Follow up: What kind of project am I working on?\n",
      "Intermediate Answer: As an AI, I do not know what kind of project you are working on.\n",
      "Follow up: What information should I consider to choose between LangChain and LlamaIndex?\n",
      "Intermediate Answer: Consider the complexity of your project, the types of data you're working with, and the specific functionalities you require. If you need broad versatility and integration capabilities, LangChain might be a better fit. If you need specialized data indexing and retrieval, especially for knowledge graphs, LlamaIndex might be preferable.\n",
      "So the final answer is: It depends on your project's needs. LangChain is more versatile, while LlamaIndex excels in data indexing and retrieval.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=question_template,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Would you rather use LangChain or LlamaIndex?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3107569",
   "metadata": {},
   "source": [
    "One caveat is that we might what to tag the final answer so that it is easier to extract if that is what we are going to present to the final user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

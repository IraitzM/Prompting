{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26159345",
   "metadata": {},
   "source": [
    "# Tracing\n",
    "\n",
    "When we deploy this type of models, one thing we would like to look into is how they are doing. \n",
    "\n",
    "There are a couple of options to do this but being already working with LangChain, probably LangSmith might be the easiest one. Do try [Opik](https://www.comet.com/site/products/opik/) though.\n",
    "\n",
    "LangSmith only requires to set a flag to start tracing but it also requires a LangSmith account as the information gets stored in their remote environment.\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_API_KEY=<your-api-key>\n",
    "```\n",
    "\n",
    "You may also want to add `LANGSMITH_ENDPOINT=https://api.smith.langchain.com` and `LANGSMITH_PROJECT=...` if you will run different projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Select a model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ab4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a few ways to translate \"Hello, how are you?\" into French, depending on the level of formality:\n",
      "\n",
      "*   **Formal:** Bonjour, comment allez-vous ? (This is the most polite and appropriate for strangers or people you don't know well.)\n",
      "\n",
      "*   **Informal:** Salut, comment vas-tu ? (This is for friends and family.)\n",
      "\n",
      "*   **Very informal:** Salut, Ã§a va ? (This is a common, casual greeting among friends.)\n",
      "\n",
      "So, the best translation depends on the context. If unsure, stick with the formal option.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create the LLM Chain using LangChain\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"Translate the following text to French: {input}\"\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# Generate the translations\n",
    "translation = chain.invoke(\"Hello, how are you?\")\n",
    "print(translation.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7cffa",
   "metadata": {},
   "source": [
    "This will end up in your LangChain console as a set of queries\n",
    "\n",
    "![langsmith](imgs/langsmithpro.png)\n",
    "\n",
    "that you can explore further and gets particularly relevant for long conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
